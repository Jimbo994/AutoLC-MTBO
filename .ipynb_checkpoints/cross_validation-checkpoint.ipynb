{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation of Single- and Multi-task Gaussian process\n",
    "\n",
    "In this notebook we will use the 2D retention model, and the online and offline system that we set up in the [previous notebook](setting_up_a_2DLC_system.ipynb) in order to empirically test our single-task and multi-task  Gaussian process models.\n",
    "\n",
    "In a nutshell:\n",
    "- We generate 24 online method parameters and 120 offline method parameters and compute their respective objective function values.\n",
    "- The single-task model is fit only to the online data.\n",
    "- The multi-task model is fit to both the online and offline data.\n",
    "- In the leave-one-out cross validation, we remove one online observation and fit the models to the remaining 19 points (plus 100 offline method parameters for the multi-task model.\n",
    "- It is shown that by incorporating the offline data, the multi-task model is much better at making correct predictions.\n",
    "\n",
    "The results and details of this notebook are described in Section 4.1 of the main paper.\n",
    "\n",
    "We start out with importing the required packages and defining the run device (GPU or CPU, defaulting to GPU if there is CUDA support)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-16T11:48:49.049362Z",
     "start_time": "2023-10-16T11:48:45.071350Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from botorch import fit_gpytorch_model\n",
    "\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.models.multitask import MultiTaskGP\n",
    "from gpytorch import ExactMarginalLogLikelihood\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "tkwargs = (\n",
    "    {  # Dictionary containing information about data type and data device\n",
    "        \"dtype\": torch.double,\n",
    "        \"device\": torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\"),\n",
    "    }\n",
    ")\n",
    "# Writing the dictionary to a DataFrame\n",
    "df = pd.DataFrame([tkwargs])\n",
    "# Saving the DataFrame to a CSV file, this will be read by other functions.\n",
    "df.to_csv('data/tkwargs.csv', index=False)\n",
    "\n",
    "from bo_code.MTBO import generate_initial_data_mtgp, add_task_feature\n",
    "from botorch.cross_validation import gen_loo_cv_folds\n",
    "from botorch.models.transforms import Standardize, Normalize\n",
    "from rm_code.retention_model import online_system, offline_system\n",
    "from utils.utils import bo_to_rm_2D, check_pars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the retention model\n",
    "\n",
    "In this cell we will set up all values related to the 2DLC sytem, such as dead time, dwell time, plate number, modulation time, etc.\n",
    "In addition, we set 1D and 2D parameters for a simple linear gradient in the first dimension, and a second dimension gradient program without a gradient shift, for later use. Lastly we set maximum times in the first and second dimension (max_T), which will be thresholds for the evaluation of objective functions later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-16T11:49:51.035893Z",
     "start_time": "2023-10-16T11:49:50.981451Z"
    }
   },
   "outputs": [],
   "source": [
    "### Set up a 1D retention model\n",
    "\n",
    "# Set some default parameters for first dimension\n",
    "t_0_1D = 4.5 # dead time\n",
    "t_D_1D = 0.1 # dwell time\n",
    "N_1D = 400 # plate number 1D\n",
    "t_init_1D = 2 # init time\n",
    "\n",
    "# create dictionary for the above described parameters\n",
    "settings_1D = {'t_0': t_0_1D, 't_D': t_D_1D, 'N': N_1D, 't_init': t_init_1D}\n",
    "\n",
    "# Try out a 1D gradient\n",
    "phi_list_1D = [0, 0.25, 0.5, 1] # phi values\n",
    "t_list_1D = [0, 25, 50, 100] # time values\n",
    "\n",
    "### Set up a 2D retention model\n",
    "\n",
    "### Define 2D parameters\n",
    "N_2D = 1000 # plate number 2D\n",
    "\n",
    "t_M_2D = 2 #/ 3 # modulation time minutes\n",
    "t_G_2D = 1.8 #/ 3 # gradient time minutes\n",
    "t_init_2D = 0.1 #/ 3 # init time minutes\n",
    "t_D_2D = 0.01 # dwell time in minutes\n",
    "t_0_2D = 0.01 # dead time in minutes\n",
    "\n",
    "# create dictionary for the above described parameters\n",
    "settings_2D = {'t_M': t_M_2D, 't_G': t_G_2D, 't_init': t_init_2D, 't_D': t_D_2D, 't_0': t_0_2D, 'N': N_2D}\n",
    "\n",
    "# Try out a shifting gradient\n",
    "phi_init_2D = [0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "phi_final_2D = [1, 1, 1, 1, 1]\n",
    "t_list_2D = [0, t_0_1D, 40, 45, t_list_1D[-1]]\n",
    "\n",
    "# something more optimal\n",
    "# Try out a 1D gradient\n",
    "phi_list_1D_opt = [0.1, 0.3, 1, 1] # phi values\n",
    "t_list_1D_opt = [0, 25, 80, 100] # time values\n",
    "\n",
    "phi_init_2D_opt = [0.1, 0.1, 0.1, 0.3, 0.4]\n",
    "phi_final_2D_opt = [0.20, 0.20, 0.2, 0.7, 1]\n",
    "t_list_2D_opt = [0, t_0_1D, 45, 50, t_list_1D[-1]]\n",
    "\n",
    "max_T = [100, t_M_2D]\n",
    "\n",
    "# check if the parameters are valid\n",
    "check_pars(settings_2D, t_list_1D, phi_init_2D, phi_final_2D, t_list_2D)\n",
    "\n",
    "# Load the retention parameters created in \"sampling_retention_paremters.ipynb\"\n",
    "ret_pars = pd.read_csv('data/2Dsample.csv').to_dict(orient='list')\n",
    "n_analytes = len(ret_pars['k0_1D'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining fixed- and optimizable parameters, bounds and inequality constraints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-16T11:49:53.150592Z",
     "start_time": "2023-10-16T11:49:53.138991Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set some fixed parameters\n",
    "#n_analytes=80 # number of analytes\n",
    "\n",
    "t_max = 100 # maximum time\n",
    "\n",
    "phi_min, phi_max = 0, 1 # maximum phi\n",
    "fixed_phi_pars_1D = torch.tensor([[phi_min], [phi_max]]) # fixed phi points\n",
    "fixed_time_pars_1D = torch.tensor([[0.], [t_max]]) # at fixed time points\n",
    "\n",
    "fixed_phi_pars_2D = torch.tensor([[phi_min], [phi_max]]) # fixed phi points\n",
    "fixed_time_pars_2D = torch.tensor([[0.],[t_0_1D], [t_max]]) # at fixed time points\n",
    "\n",
    "# Pars vector will look like this: [phi1, phi2, t1, t2, phi_i1, phi_i2, phi_i3, phi_f1, phi_f2, phi_f3, t1_shift, t2_shift]\n",
    "bounds = torch.stack([\n",
    "    torch.tensor([phi_min, phi_min, 0.1, 0.1, phi_min, phi_min, phi_min, phi_min, phi_min, phi_min, t_0_1D, t_0_1D]),\n",
    "    torch.tensor([phi_max, phi_max, t_max-0.1, t_max-0.1, phi_max, phi_max, phi_max, phi_max, phi_max, phi_max, t_max-t_M_2D, t_max-t_M_2D])]\n",
    ")\n",
    "\n",
    "# bounds after normalization to [0,1]\n",
    "norm_bounds = torch.stack([torch.zeros(12), torch.ones(12)])\n",
    "\n",
    "inequality_constraints= [(torch.tensor([0,1]), torch.tensor([-1., 1.]), 0.0), (torch.tensor([2,3]), torch.tensor([-1., 1.]), 0.1), (torch.tensor([10,11]), torch.tensor([-1., 1.]), t_M_2D), (torch.tensor([4,8]), torch.tensor([-1., 1.]), 0.0), (torch.tensor([5,9]), torch.tensor([-1., 1.]), 0.0)]\n",
    "\n",
    "# missing analytes and noise for offline system.\n",
    "# draw 10 random indices between 0 and n_analytes\n",
    "remove_indices = np.random.randint(0, n_analytes, 30)\n",
    "# create dictionary with noise levels\n",
    "noise = {'tR_1D': 0.3, 'tR_2D': 0.05, 'W_1D': 0.2, 'W_2D': 0.01}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a dataset\n",
    "\n",
    "We will now sample method parameters for the online and offline system and will evaluate these method parameters on the online and offline system respectively, to generate a dataset on which to perform leave-one-out cross validation using our GP models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-16T11:53:24.916185Z",
     "start_time": "2023-10-16T11:52:36.297825Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:07<00:00,  3.11it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 120/120 [00:32<00:00,  3.70it/s]\n"
     ]
    }
   ],
   "source": [
    "# what we want to do here is to create a bunch of training data, both online and offline.\n",
    "# then fit these models using multi-task and single-task GPs, and plot correlation plots.\n",
    "\n",
    "# generate initial samples\n",
    "n_init_online = 24\n",
    "n_init_offline = 120\n",
    "\n",
    "pars_online_init, pars_offline_init = generate_initial_data_mtgp(n_init_online, n_init_offline, bounds, inequality_constraints)\n",
    "\n",
    "# create lists to fill with results per trial\n",
    "scores_single_task = []\n",
    "scores_online_mt = []\n",
    "scores_offline_mt = []\n",
    "\n",
    "pars_single_task = []\n",
    "pars_online_mt = []\n",
    "pars_offline_mt = []\n",
    "\n",
    "# Perform initial online experiments\n",
    "phi_list_1D, t_list_1D, phi_init_2D, phi_final_2D, t_list_2D = bo_to_rm_2D(pars_online_init, fixed_phi_pars_1D, fixed_time_pars_1D, fixed_phi_pars_2D, fixed_time_pars_2D)\n",
    "\n",
    "for i in tqdm(range(len(pars_online_init))):\n",
    "    tR_list_1D, W_list_1D, tR_list_2D, W_list_2D, res_score, time_score = online_system(ret_pars, settings_1D, settings_2D, phi_list_1D[i], t_list_1D[i],phi_init_2D[i], phi_final_2D[i], t_list_2D[i], max_T)\n",
    "\n",
    "    # now we need to add the pars and scores to online_mt and single_task as they will both share the same initial experiments\n",
    "    scores_online_mt.append(res_score)\n",
    "    pars_online_mt.append(pars_online_init[i])\n",
    "\n",
    "    scores_single_task.append(res_score)\n",
    "    pars_single_task.append(pars_online_init[i])\n",
    "\n",
    "# Perform initial offline experiments\n",
    "phi_list_1D, t_list_1D, phi_init_2D, phi_final_2D, t_list_2D = bo_to_rm_2D(pars_offline_init, fixed_phi_pars_1D, fixed_time_pars_1D, fixed_phi_pars_2D, fixed_time_pars_2D)\n",
    "\n",
    "for i in tqdm(range(len(pars_offline_init))):\n",
    "\n",
    "    tR_list_1D, W_list_1D, tR_list_2D, W_list_2D, res_score, time_score = offline_system(ret_pars, settings_1D, settings_2D, phi_list_1D[i], t_list_1D[i],phi_init_2D[i], phi_final_2D[i], t_list_2D[i], max_T, noise, remove_indices)\n",
    "\n",
    "    # now we need to add the pars and scores to offline_mt\n",
    "    scores_offline_mt.append(res_score)\n",
    "    pars_offline_mt.append(pars_offline_init[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave-one-out cross validation on the Multi-Task Gaussian process model\n",
    "\n",
    "We will now perform leave-one-out cross validation for the Multi-Task GP. This is done by generating cross folds of 19 online training points and 1 online test points, for 20 folds. The model will have access to all 400 offline trainng points.\n",
    "\n",
    "The model is then fit on the training points, and the fitted model is used to predict the test point. This is then repeated for all folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-16T11:53:52.706117Z",
     "start_time": "2023-10-16T11:53:24.925110Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████████████████████▋                                                                                                                                                                                   | 3/24 [00:03<00:24,  1.15s/it]"
     ]
    }
   ],
   "source": [
    "cv_results_mt = pd.DataFrame()\n",
    "# create leave-one-out cross folds\n",
    "cv_folds = gen_loo_cv_folds(pars_online_init.to(**tkwargs), torch.tensor(scores_online_mt).unsqueeze(-1).to(**tkwargs))\n",
    "\n",
    "for i in tqdm(range(len(cv_folds.train_X))):\n",
    "    # need to add the task feature to the training data using add_task_feature\n",
    "    tr_X = add_task_feature(cv_folds.train_X[i].to(**tkwargs), 0)\n",
    "    # add task feature to the offline data\n",
    "    tr_X_offline = add_task_feature(torch.tensor(pars_offline_init).to(**tkwargs), 1)\n",
    "    # need to add the offline data to the training data\n",
    "    tr_X = torch.cat((tr_X, tr_X_offline), 0).to(**tkwargs)\n",
    "    tr_Y = torch.cat((cv_folds.train_Y[i], torch.tensor(scores_offline_mt).unsqueeze(-1).to(**tkwargs)), 0)\n",
    "\n",
    "    te_X = cv_folds.test_X[i]\n",
    "    # add_task_feature\n",
    "    te_X = add_task_feature(te_X, 0)\n",
    "\n",
    "    te_Y = cv_folds.test_Y[i]\n",
    "\n",
    "    model = MultiTaskGP(tr_X, tr_Y, task_feature=-1, outcome_transform=Standardize(m=1),\n",
    "                        input_transform=Normalize(d=tr_X.shape[-1], bounds=bounds,\n",
    "                        indices=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]))\n",
    "    model_mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "    fit_gpytorch_model(model_mll)\n",
    "\n",
    "        # Evaluate model on test data\n",
    "    with torch.no_grad():\n",
    "        observed_pred = model.posterior(te_X[:, :-1], te_X[:, -1])\n",
    "\n",
    "    # write results from posterior to cv_results dataframe\n",
    "    cv_results_mt = pd.concat([cv_results_mt, pd.DataFrame({'mean': observed_pred.mean[0].cpu(), 'lower': observed_pred.mvn.confidence_region()[0].cpu(),\n",
    "                                                            'upper': observed_pred.mvn.confidence_region()[1].cpu(), 'true': te_Y[0].cpu(), 'task': te_X[:, -1].cpu()})])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-16T11:53:52.713822Z",
     "start_time": "2023-10-16T11:53:52.709151Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(model.task_covar_module.covar_factor)\n",
    "# cf = model.task_covar_module.covar_factor.detach().cpu()\n",
    "# var = model.task_covar_module.var.detach().cpu()\n",
    "# print(model.task_covar_module.covar_matrix())\n",
    "# print(model.covar_module.outputscale)\n",
    "#cf @ cf.transpose(-1, -2) + torch.diag_embed(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave-one-out cross validation on the single-task Gaussian process model\n",
    "\n",
    "Likewise, we perform leave-one-out cross validation for the single task model, which is only trained on the online data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-16T11:53:57.190999Z",
     "start_time": "2023-10-16T11:53:52.723346Z"
    }
   },
   "outputs": [],
   "source": [
    "cv_results_gp1 = pd.DataFrame()\n",
    "\n",
    "for i in tqdm(range(len(cv_folds.train_X))):\n",
    "    tr_X = cv_folds.train_X[i]\n",
    "    tr_Y = cv_folds.train_Y[i]\n",
    "    te_X = cv_folds.test_X[i]\n",
    "    te_Y = cv_folds.test_Y[i]\n",
    "\n",
    "    # Fit model on training data\n",
    "    model = SingleTaskGP(tr_X, tr_Y, input_transform=Normalize(d=len(bounds[0]), bounds=bounds), outcome_transform=Standardize(m=1))\n",
    "    model_mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "    fit_gpytorch_model(model_mll)\n",
    "\n",
    "    # Evaluate model on test data\n",
    "    with torch.no_grad():\n",
    "        observed_pred = model.posterior(te_X)\n",
    "\n",
    "    # # write results from posterior to cv_results dataframe\n",
    "    cv_results_gp1 = pd.concat([cv_results_gp1, pd.DataFrame({'mean': observed_pred.mean[0].cpu(), 'lower': observed_pred.mvn.confidence_region()[0].cpu(),\n",
    "                                                            'upper': observed_pred.mvn.confidence_region()[1].cpu(), 'true': te_Y[0].cpu()})])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize results\n",
    "\n",
    "We now visualize the results of the leave-one-out cross validation. It can be observed that the single-task GP fit only to the online data is struggling to make reliable predictions, due to the relatively high dimensionality and limited data. The multi-task model, fit to both the online and (biased) offline data allows for more accurate predictions.\n",
    "Therefore, the multi-task model will likely be a better model in the Bayesian optimization loop that we will use in the [next notebook](2dlc_rm.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-16T11:54:16.556382Z",
     "start_time": "2023-10-16T11:54:16.549461Z"
    }
   },
   "outputs": [],
   "source": [
    "# plotting functionality\n",
    "def min_max_cross_val_plot(df):\n",
    "    # get min and max of all columns for plot bounds\n",
    "    min_val = min(df['lower']) - 0.2\n",
    "    max_val = max(df['upper']) + 0.2\n",
    "    return min_val, max_val\n",
    "\n",
    "def plot_cross_val(df, title):\n",
    "    # plot the cross validation results\n",
    "    fig, ax = plt.subplots()\n",
    "    min_val, max_val = min_max_cross_val_plot(df)\n",
    "    min_val, max_val = 0, 150\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylim([min_val, max_val])\n",
    "    ax.set_xlim([min_val, max_val])\n",
    "    ax.set_xlabel(\"Observed value\")\n",
    "    ax.set_ylabel(\"Predicted value\")\n",
    "\n",
    "    ax.errorbar(\n",
    "        x=df['true'],\n",
    "        y= df['mean'],\n",
    "        xerr=0,\n",
    "        yerr=((df['upper'] - df['lower'])/2),\n",
    "        fmt='o',\n",
    "        ecolor='tab:blue',\n",
    "        mec='white',\n",
    "    )\n",
    "    ax.plot([min_val, max_val], [min_val, max_val], 'k--', lw=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-16T11:54:17.926907Z",
     "start_time": "2023-10-16T11:54:17.583168Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(font_scale=1.5)\n",
    "sns.set_style('white')\n",
    "\n",
    "plot_cross_val(cv_results_mt[cv_results_mt['task'] == 0], 'Multi-Task GP online task')\n",
    "plt.tight_layout()\n",
    "# annote plot with B\n",
    "plt.annotate('B', xy=(0.05, 0.9), xycoords='axes fraction', fontsize=20)\n",
    "# save figure\n",
    "# plt.savefig('figures/cross_val_multi_task.pdf', dpi=500, bbox_inches='tight')\n",
    "# plt.savefig('figures/cross_val_multi_task.png', dpi=500, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-16T11:54:20.752965Z",
     "start_time": "2023-10-16T11:54:20.460289Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_cross_val(cv_results_gp1, 'Single-Task GP online task')\n",
    "plt.tight_layout()\n",
    "# annotate plot with A\n",
    "plt.annotate('A', xy=(0.05, 0.9), xycoords='axes fraction', fontsize=20)\n",
    "# save figure\n",
    "# plt.savefig('figures/cross_val_single_task.pdf', dpi=500, bbox_inches='tight')\n",
    "# plt.savefig('figures/cross_val_single_task.png', dpi=500, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MultiTask2DLCSimulation",
   "language": "python",
   "name": "multitask2dlcsimulation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
